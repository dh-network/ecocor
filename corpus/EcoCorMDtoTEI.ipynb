{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f9b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3323d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344c9580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fc64d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02990208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikidataintegrator as wdi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c1595c",
   "metadata": {},
   "source": [
    "# Conversion to TEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "202ac934",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TEI:\n",
    "    \"\"\" EcoCor TEI document object\"\"\"\n",
    "    langmap = {'Englisch':'en', \n",
    "               'Deutsch':'de',\n",
    "               'Orig. Franz. / Englisch': 'en'\n",
    "              }\n",
    "    authors_formatted = {}\n",
    "    teiid = 1\n",
    "    def __init__(self, title, author, sourcetxtname):\n",
    "        self.title = title\n",
    "        print(title)\n",
    "        self.author = author\n",
    "        self.empty = False\n",
    "        self.sourcetxtname = sourcetxtname.replace('.txt','')\n",
    "        #print(self.sourcetxtname)\n",
    "        if sourcetxtname != 'NoSourceTxt':\n",
    "            self.sourcetxtpath = f'ecocorMD/{self.sourcetxtname}.txt'\n",
    "            self.outputfilename = self.sourcetxtname\n",
    "            if not os.path.exists(self.sourcetxtpath):\n",
    "                #print(sourcetxtname)\n",
    "                #print(self.sourcetxtpath)\n",
    "                self.empty = True\n",
    "        else:\n",
    "            self.empty = True\n",
    "            self.sourcetxtpath = None\n",
    "            self.outputfilename = title\n",
    "        self.outputfilename = self.outputfilename.replace(' ', '')\n",
    "            \n",
    "        self.year = None\n",
    "        self.wikidataid = None\n",
    "        self.wikidataidauth = None\n",
    "        self.lang = 'Undefined'\n",
    "        with open('aux/EcoStub.xml') as ecostub:\n",
    "            stubsoup = BeautifulSoup(ecostub, 'xml')\n",
    "        self.tree = stubsoup\n",
    "        self.len_words = 0\n",
    "    \n",
    "    def isolang(self):\n",
    "        return self.langmap.get(self.lang)\n",
    "    \n",
    "    def measure_length(self, text):\n",
    "        length = len(re.findall(r'\\b\\w.*?\\b', text))\n",
    "        #print(length)\n",
    "        return length \n",
    "    \n",
    "    def heur_conv(self, auth_string):\n",
    "        '''heuristic conversion of author string for those who have no wikidata'''\n",
    "        probable_surname = auth_string[-1:]\n",
    "        rest = auth_string[:-1]\n",
    "        return f'{probable_surname}, {rest}'\n",
    "    \n",
    "    def wikify_tree(self, treetitle, treeauthor):\n",
    "        treeauthor.clear() # remove text from stub\n",
    "        if 'entity/Q' not in self.wikidataidauth:\n",
    "            auth_corr_format = self.heur_conv(self.author)\n",
    "        elif self.wikidataidauth not in TEI.authors_formatted:\n",
    "            auth_corr_format = get_author_correct_format(self.wikidataidauth)\n",
    "            TEI.authors_formatted[self.wikidataidauth] = auth_corr_format\n",
    "        else:\n",
    "            auth_corr_format = TEI.authors_formatted[self.wikidataidauth] \n",
    "        treeauthor.append(auth_corr_format)\n",
    "        treeauthor['ref'] = self.wikidataidauth\n",
    "        treetitle['ref'] = self.wikidataid\n",
    "        \n",
    "    def checksubchapterheader(self, paragraph):\n",
    "        if paragraph.startswith('###'):\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def checkchapterheader(self, paragraph):\n",
    "        if paragraph.startswith('##') and not paragraph.startswith('###'):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def checkpartheader(self, paragraph):\n",
    "        if paragraph.startswith('#') and not paragraph.startswith('##'):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    \n",
    "    def checkfront(self, paragraph):\n",
    "        if paragraph.startswith('^'):\n",
    "            #print('front')\n",
    "            #print(paragraph)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def get_paragraph_id(self, count):\n",
    "        return f'{self.get_full_id()}_{count*10}'        \n",
    "        \n",
    "        \n",
    "    def add_text(self):\n",
    "        teitext = self.tree.find('text')\n",
    "        teitext.clear()\n",
    "        body = self.tree.new_tag('body')\n",
    "        toptag = body\n",
    "        currentdiv = body\n",
    "        if self.sourcetxtpath == None:\n",
    "            self.empty = True\n",
    "            return 'NoText'\n",
    "        if not os.path.exists(self.sourcetxtpath):\n",
    "            self.empty = True\n",
    "            #print(self.sourcetxtpath)\n",
    "            return 'NoText'\n",
    "        with open(self.sourcetxtpath) as opensourcefile:\n",
    "            #text_raw = opensourcefile.read()\n",
    "            text_to_insert = opensourcefile.readlines()\n",
    "            text_raw = '\\n'.join(text_to_insert)\n",
    "        #print(text_raw)[:20]\n",
    "        #print(text_to_insert)[:2]\n",
    "        self.len_words = self.measure_length(text_raw)\n",
    "        pcount=1\n",
    "        for paragraph in text_to_insert:\n",
    "            if self.checksubchapterheader(paragraph):\n",
    "                div = self.tree.new_tag('div')\n",
    "                head = self.tree.new_tag('head')\n",
    "                head.append(paragraph.strip('#'))\n",
    "                div['type'] = 'subchapter'\n",
    "                div.append(head)\n",
    "                chapter.append(div)\n",
    "                currentdiv = div\n",
    "            elif self.checkchapterheader(paragraph):\n",
    "                div = self.tree.new_tag('div')\n",
    "                head = self.tree.new_tag('head')\n",
    "                head.append(paragraph.strip('#'))\n",
    "                div['type'] = 'chapter'\n",
    "                div.append(head)\n",
    "                toptag.append(div)\n",
    "                chapter = div\n",
    "                currentdiv = div\n",
    "            elif self.checkpartheader(paragraph):\n",
    "                div = self.tree.new_tag('div')\n",
    "                head = self.tree.new_tag('head')\n",
    "                head.append(paragraph.strip('#'))\n",
    "                div['type'] = 'group'\n",
    "                div.append(head)\n",
    "                body.append(div)\n",
    "                toptag = div\n",
    "                currentdiv = div\n",
    "                #print('Div found')\n",
    "                #print(self.title)\n",
    "            elif self.checkfront(paragraph):\n",
    "                front = self.tree.new_tag('front')\n",
    "                p = self.tree.new_tag('p')\n",
    "                p['xml:id'] = self.get_paragraph_id(pcount)\n",
    "                pcount+=1\n",
    "                p.append(paragraph.strip('^ \\n'))\n",
    "                if len(paragraph.strip('^')) > 0:\n",
    "                    front.append(p)\n",
    "                teitext.append(front)\n",
    "                currentdiv = front\n",
    "            else:\n",
    "                p = self.tree.new_tag('p')\n",
    "                p['xml:id'] = self.get_paragraph_id(pcount)\n",
    "                pcount+=1\n",
    "                p.append(paragraph)\n",
    "                if len(paragraph.strip()) > 0: \n",
    "                    currentdiv.append(p)\n",
    "        teitext.append(body)\n",
    "    \n",
    "    def get_full_id(self):\n",
    "        numzeros = 5 if TEI.teiid < 10 else 4\n",
    "        return f'eco_{self.isolang()}_{\"0\"*numzeros}{TEI.teiid}'\n",
    "    \n",
    "    def update_tree(self):\n",
    "        #def updatetag(tagname, tagcontent):\n",
    "        #    treetag = self.tree.find(tagname)\n",
    "            \n",
    "        treetitle = self.tree.find('title') # find title tag in the stub\n",
    "        treetitle.clear() # remove text from stub\n",
    "        treetitle.append(self.title) # add current title\n",
    "        \n",
    "        sdesc = self.tree.find('sourceDesc')\n",
    "        for bibl in sdesc.findAll('bibl'):\n",
    "            if 'type' in bibl.attrs:\n",
    "                if bibl['type'] == 'firstEdition':\n",
    "                    thisdate = bibl.find('date')\n",
    "                    thisdate.append(str(self.year))\n",
    "                    thisdate['when'] = str(self.year)[:4]\n",
    "        \n",
    "        \n",
    "        treeauthor = self.tree.find('author')\n",
    "        self.wikify_tree(treetitle, treeauthor) ## add wikidata links\n",
    "        \n",
    "        self.add_text()\n",
    "        #print(self.tree.find('body'))\n",
    "        \n",
    "        numpages = self.tree.find('measure')\n",
    "        numpages.clear()\n",
    "        numpages.append(str(self.len_words))\n",
    "        \n",
    "        root = self.tree.find('TEI')\n",
    "        root['xml:id'] = self.get_full_id()\n",
    "        TEI.teiid+=1\n",
    "        #print(self.isolang())\n",
    "        root['xml:lang'] = self.isolang()\n",
    "    \n",
    "    \n",
    "    def serialize(self):\n",
    "        \"\"\"SERIALISATION\"\"\"\n",
    "        self.update_tree()\n",
    "        return self.tree.prettify()\n",
    "    \n",
    "    def choose_folder(self):\n",
    "        if self.empty:\n",
    "            return 'no_text_yet' \n",
    "        return 'has_text'\n",
    "        \n",
    "    def output_TEI(self):\n",
    "        with open(f'tei/{self.isolang()}/{self.choose_folder()}/{self.outputfilename}.xml', \n",
    "                  'w') as outfile:\n",
    "            outfile.write(self.serialize())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0d51794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_tei(row):\n",
    "    author = row['Autor*in']\n",
    "    title = row['Titel']\n",
    "    sourcetxtname = row['Filename']\n",
    "    new_tei = TEI(title, author, sourcetxtname)\n",
    "    new_tei.year = row['Jahr']\n",
    "    new_tei.wikidataid = row['Wiki-Data ID Work'].replace('/wiki/','/entity/')\n",
    "    new_tei.wikidataidauth = f'https://www.wikidata.org/entity/{row[\"Wiki-Data ID Author\"]}'\n",
    "    new_tei.lang = row['Sprache']\n",
    "    new_tei.output_TEI()\n",
    "    return f'{sourcetxtname} success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5676d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('aux/EcoCorMetadata.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a2f61245",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Filename'] = df['Filename'].fillna('NoSourceTxt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08aa17c",
   "metadata": {},
   "source": [
    "### Getting normalized author string in eltec format \n",
    "https://github.com/dracor-org/eco_en/issues/4\n",
    "\n",
    "When used within a [], an author's name is given in a standardized format (surname, forename/s, (YYYY-YYYY)) as shown in this example.\n",
    "`<author ref=\"viaf:31996364\">Forster, Edward Morgan (1879-1970)</author>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f33a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_wikidata_for_author_data(auth_wikidata_id):\n",
    "    qwr = f\"\"\"\n",
    "    SELECT ?family_nameLabel ?given_nameLabel ?dob ?dod\n",
    "    WHERE {{\n",
    "      wd:{auth_wikidata_id} wdt:P735 ?given_name.\n",
    "      wd:{auth_wikidata_id} wdt:P734 ?family_name.\n",
    "      wd:{auth_wikidata_id} wdt:P569 ?dob.\n",
    "      wd:{auth_wikidata_id} wdt:P570 ?dod.\n",
    "\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    jsonresult = wdi.wdi_core.WDItemEngine.execute_sparql_query(qwr)\n",
    "        \n",
    "    #with open('sample.json', 'w') as openfile:\n",
    "    #    json.dump(jsonresult, openfile, indent=4)\n",
    "    return jsonresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e3e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_correct_format(wikidata_id):\n",
    "    wikidata_id = wikidata_id.replace('https://www.wikidata.org/entity/','')\n",
    "    for item in query_wikidata_for_author_data(wikidata_id)['results']['bindings']:\n",
    "        surname = item['family_nameLabel']['value']\n",
    "        name = item['given_nameLabel']['value']\n",
    "        yob = item['dob']['value'][:4]\n",
    "        yod = item['dod']['value'][:4]\n",
    "    return f'{surname}, {name} ({yob}-{yod})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d451dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_author_correct_format('Q5879')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee3668b",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c3d79a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utopia\n",
      "Nova Atlantis\n",
      "Robinson Crusoe\n",
      "The Mysteries of Udolpho\n",
      "Frankenstein\n",
      "Moby-Dick\n",
      "The Last Man\n",
      "The Paradise of Bachelors and the Tartarus of Maids\n",
      "Little House on the Prairie\n",
      "Paris in the Twentieth Century\n",
      "The Purchase of the North Pole\n",
      "Tess of the d’Urbervilles \n",
      "The American Claimant \n",
      "Earth Revisited\n",
      "The Aerial Brickfield\n",
      "Dracula\n",
      "A Corner in Lightning\n",
      "The Wreck of the South Pole, or the Great Dissembler \n",
      "Heart of Darkness\n",
      "The White Battalions\n",
      "The Evacuation of England: The Twist in the Gulf Stream\n",
      "The Great Weather Syndicate \n",
      "England's The Air Trust\n",
      "The Man Who Rocked The Earth\n",
      "Erewhon\n",
      "Wuthering Heights\n",
      "After London, or Wild England\n",
      "The Hoosier Schoolmaster: A Story of Backwoods Life in Indiana\n",
      "Deephaven\n",
      "A Crystal Age\n",
      "Wilhelm Meisters Lehrjahre\n",
      "Heinrich von Ofterdingen\n",
      "Das Erdbeben in Chili\n",
      "Die Elfen\n",
      "Das fremde Kind\n",
      "Die Bergwerke zu Falun\n",
      "Lebens-Ansichten des Katers Murr\n",
      "Wilhelm Meisters Wanderjahre\n",
      "Die Judenbuche\n",
      "Der Hochwald\n",
      "Bunte Steine\n",
      "Der Grüne Heinrich (zweite Fassung)\n",
      "Nachsommer\n",
      "Waldwinkel\n",
      "Sturmflut\n",
      "Die Leute von Seldwyla\n",
      "Das Sinngedicht\n",
      "Pfisters Mühle\n",
      "Martin Salander\n",
      "Der Schimmelreiter \n",
      "Stechlin\n",
      "Berufstragik\n",
      "Der Tunnel\n",
      "Lesabéndio. Ein Asteroiden-Roman\n",
      "Ein Bericht für eine Akademie\n",
      "Berge Meere und Giganten\n",
      "Unter den Dolomiten\n",
      "Ansichten der Natur\n",
      "Ansichten vom Niederrhein von Brabant, Flandern, Holland, England und Frankreich im April, Mai und Junius \n",
      "Wanderungen durch die Mark Brandenburg\n",
      "Die Lehrlinge von Sais\n",
      "Italienische Reise\n",
      "Harzreise\n",
      "Reise um die Welt\n",
      "The Natural History and Antiquities of Selborne\n",
      "Rural Hours\n",
      "Walden\n",
      "My First Summer in the Sierra\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                 NoSourceTxt success\n",
       "1                                 NoSourceTxt success\n",
       "2                                 NoSourceTxt success\n",
       "3                      1794_Radcliffe_Udolpho success\n",
       "4                   1818_Shelley_Frankenstein success\n",
       "                           ...                       \n",
       "63            1836_Chamisso_Reise-um-die-Welt success\n",
       "64     1789_White_Natural-History-of-Selborne success\n",
       "65                    1850_Cooper_Rural-Hours success\n",
       "66                        1854_Thoreau_Walden success\n",
       "67    1911_Muir_My-First-Summer-in-the-Sierra success\n",
       "Length: 68, dtype: object"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEI.teiid = 1\n",
    "df.apply(row_to_tei, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cfb03a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
